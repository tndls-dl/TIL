# ğŸ¤– Machine Learning

## âœï¸ DAY 02

## ğŸ² Logistic Regression

## ğŸ§¹ ë°ì´í„° ì¤€ë¹„

- ë°ì´í„°: `fish_data.csv`
- ì…ë ¥ ë³€ìˆ˜: Weight, Length, Diagonal, Height, Width
- ì¶œë ¥ ë³€ìˆ˜: Species (ìƒì„  ì¢…ë¥˜)
- í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„ë¦¬ í›„ **ìŠ¤ì¼€ì¼ë§(StandardScaler)** ì ìš©

---

## ğŸ§  KNN ë³µìŠµ

- `KNeighborsClassifier(n_neighbors=3)`
- íŠ¹ì • ë°ì´í„° ì£¼ìœ„ 3ê°œì˜ ì´ì›ƒìœ¼ë¡œ í™•ë¥  ê³„ì‚°
- `predict_proba()` â†’ ê° í´ë˜ìŠ¤ì¼ í™•ë¥  ë°˜í™˜
- `classes_` ì†ì„±: ë¶„ë¥˜ ê°€ëŠ¥í•œ í´ë˜ìŠ¤ ëª©ë¡

ğŸ§‘â€ğŸ’» ì˜ˆì‹œ ì½”ë“œ

```python
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier(n_neighbors=3)
kn.fit(X_train, y_train)

print(kn.score(X_train, y_train), kn.score(X_test, y_test))
print(kn.classes_)
print(kn.predict(X_test[:5]))
print(kn.predict_proba(X_test[:5]))
```

---

## ğŸ’¡ ë¡œì§€ìŠ¤í‹± íšŒê·€ ê°œë…

- ì´ë¦„ì€ íšŒê·€(Regression)ì´ì§€ë§Œ ì‹¤ì œë¡œëŠ” **ë¶„ë¥˜(Classification) ëª¨ë¸**
- ì„ í˜• ë°©ì •ì‹ `z` ê³„ì‚° í›„:
    - **ì´ì§„ë¶„ë¥˜** â†’ ì‹œê·¸ëª¨ì´ë“œ(sigmoid) í•¨ìˆ˜
    - **ë‹¤ì¤‘ë¶„ë¥˜** â†’ ì†Œí”„íŠ¸ë§¥ìŠ¤(softmax) í•¨ìˆ˜
- ì¶œë ¥: í™•ë¥  (0~1), ê°€ì¥ í° í™•ë¥ ì˜ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡

ğŸ§‘â€ğŸ’» ì‹œê·¸ëª¨ì´ë“œ

```python
phi(z) = 1 / (1 + e^(-z))
```

ğŸ§‘â€ğŸ’» ì†Œí”„íŠ¸ë§¥ìŠ¤

```python
Ïƒ(z_i) = exp(z_i) / Î£_j exp(z_j)
```

---

## ğŸ£ ì´ì§„ ë¶„ë¥˜ (ë¹™ì–´ vs ë„ë¯¸)

- `LogisticRegression()` í•™ìŠµ
- ê²°ê³¼: `coef_`, `intercept_` â†’ ë°©ì •ì‹ ê³„ìˆ˜
- `decision_function()` : zê°’ ë°˜í™˜
- `expit()` : ì§ì ‘ ì‹œê·¸ëª¨ì´ë“œ ì ìš© ê°€ëŠ¥
- `predict_proba()` : í´ë˜ìŠ¤ í™•ë¥  ë°˜í™˜
    
    âš ï¸ í´ë˜ìŠ¤ëŠ” **ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì •ë ¬ë¨** â†’ ê¸°ì¤€ í´ë˜ìŠ¤ í™•ì¸ í•„ìš”
    

ğŸ§‘â€ğŸ’» ì˜ˆì‹œ ì½”ë“œ

```python
from sklearn.linear_model import LogisticRegression
from scipy.special import expit

lr = LogisticRegression()
lr.fit(X_bream_smelt_train, y_bream_smelt_train)

print(lr.coef_, lr.intercept_)
print(lr.classes_)
print(lr.predict(X_bream_smelt_train[:5]))

decisions = lr.decision_function(X_bream_smelt_train[:5])
print(expit(decisions))
print(lr.predict_proba(X_bream_smelt_train[:5]))
```

---

## ğŸ£ ë‹¤ì¤‘ ë¶„ë¥˜ (7ì¢… ìƒì„ )

- `LogisticRegression(C=20, max_iter=1000)`
- One-vs-Rest(OVR) ë°©ì‹ â†’ ê° í´ë˜ìŠ¤ë³„ ë°©ì •ì‹ í•™ìŠµ
- `decision_function()` : ê° í´ë˜ìŠ¤ë³„ zê°’
- `predict_proba()` : softmax ì ìš©ëœ í™•ë¥  ë°˜í™˜
- `coef_` : ì–´ë–¤ í”¼ì²˜ê°€ ì–´ë–¤ ìƒì„  ë¶„ë¥˜ì— ì˜í–¥ì„ ì£¼ëŠ”ì§€ í•´ì„ ê°€ëŠ¥

ğŸ§‘â€ğŸ’» ì˜ˆì‹œ ì½”ë“œ

```python
lr = LogisticRegression(C=20, max_iter=1000)
lr.fit(X_train_s, y_train)

print(lr.score(X_train_s, y_train))
print(lr.score(X_test_s, y_test))

print(lr.classes_)
print(lr.predict_proba(X_test_s[:3]))
print(lr.coef_)
```

---

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°

- **C (ê·œì œ ê°•ë„, Inverse of Regularization Strength)**
    - ê°’ â†‘ â†’ ê·œì œ ì•½í™” â†’ ê³¼ì í•© ìœ„í—˜ â†‘
    - ê°’ â†“ â†’ ê·œì œ ê°•í™” â†’ ì¼ë°˜í™” â†‘ (ê³¼ì†Œì í•© ìœ„í—˜ â†‘)
- **max_iter** : ìµœì í™” ë°˜ë³µ íšŸìˆ˜ (ë°ì´í„° í¬ë©´ í¬ê²Œ ì„¤ì • í•„ìš”)

---

## ğŸ“Œ ì‹¤ë¬´ ì ìš© íŒ

- ìŠ¤ì¼€ì¼ë§ í•„ìˆ˜ : ë³€ìˆ˜ í¬ê¸° ì°¨ì´ì— ë¯¼ê°
- ê³„ìˆ˜(`coef_`) í•´ì„
    - ì–‘ìˆ˜ â†’ í”¼ì²˜ â†‘ â†’ íŠ¹ì • í´ë˜ìŠ¤ í™•ë¥  â†‘
    - ìŒìˆ˜ â†’ í”¼ì²˜ â†‘ â†’ íŠ¹ì • í´ë˜ìŠ¤ í™•ë¥  â†“
- ê·œì œ í™œìš©
    - L2 ê·œì œ (Ridge, ê¸°ë³¸)
    - L1 ê·œì œ (Lasso) â†’ ë³€ìˆ˜ ì„ íƒ íš¨ê³¼

---

## âœ… í•µì‹¬ ì •ë¦¬

- ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” **ë¶„ë¥˜ ëª¨ë¸**
- ì´ì§„ë¶„ë¥˜ â†’ ì‹œê·¸ëª¨ì´ë“œ / ë‹¤ì¤‘ë¶„ë¥˜ â†’ ì†Œí”„íŠ¸ë§¥ìŠ¤
- `decision_function()` â†’ zê°’, `predict_proba()` â†’ í™•ë¥ 
- **C** íŒŒë¼ë¯¸í„°ë¡œ ê·œì œ ì¡°ì • â†’ ê³¼ì í•©/ê³¼ì†Œì í•© ì œì–´
- ë‹¨ìˆœ ì •í™•ë„ë³´ë‹¤ **AUC, F1** ë“± ì§€í‘œ í™œìš©
- `coef_` í•´ì„ìœ¼ë¡œ ì–´ë–¤ í”¼ì²˜ê°€ ì¤‘ìš”í•œì§€ í™•ì¸ ê°€ëŠ¥