# ğŸª„ Langchain

## âœï¸ DAY 01

## ğŸ”— LangChain

### ğŸ’¡ í•µì‹¬ ê°œë…

- **LangChain**: LLMì„ ì™¸ë¶€ ë°ì´í„°Â·ì»´í¬ë„ŒíŠ¸ì™€ ì—°ê²°í•´ ê°•ë ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë§Œë“œëŠ” í”„ë ˆì„ì›Œí¬
- ì£¼ìš” êµ¬ì„± ìš”ì†Œ:
    - **LLM/Chat Model**: GPT ê°™ì€ ì–¸ì–´ ëª¨ë¸ (`ChatOpenAI`)
    - **Prompt Template**: ë™ì ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ëŠ” í…œí”Œë¦¿
    - **Output Parser**: LLM ì¶œë ¥(ì˜ˆ: AIMessage)ì„ string/JSON ë“± ì›í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    - **Chain (LCEL)**: ìœ„ ìš”ì†Œë“¤ì„ `|` ì—°ì‚°ìë¡œ ì—°ê²°í•œ ì‹¤í–‰ íë¦„

**ğŸ‘©â€ğŸ’» ì½”ë“œ ì˜ˆì‹œ**

```python
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

load_dotenv()
llm = ChatOpenAI(model="gpt-4.1-nano")
```

### âš™ï¸ ì‹¤í–‰ ë°©ì‹

- `invoke`: ë‹¨ì¼ ì…ë ¥ â†’ ë‹¨ì¼ ì¶œë ¥
- `stream`: í† í° ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
- `batch`: ì—¬ëŸ¬ ì…ë ¥ì„ ë™ì‹œì— ì²˜ë¦¬

```python
response = llm.invoke("Hello, world!")  # ë‹¨ì¼ í˜¸ì¶œ
print(response.content)
```

---

## ğŸ§© í”„ë¡¬í”„íŠ¸ ë‹¤ë£¨ê¸°

### ğŸ“ PromptTemplate (ë‹¨ë°œì„±)

- `{ë³€ìˆ˜}` í˜•íƒœë¡œ ì…ë ¥ê°’ì„ ë°›ì„ ìˆ˜ ìˆìŒ

```python
from langchain_core.prompts import PromptTemplate
template = "{country}ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?"
prompt = PromptTemplate.from_template(template)

chain = prompt | llm
print(chain.invoke({"country": "ëŒ€í•œë¯¼êµ­"}).content)
```

**ğŸ‘‰ ì‹¤í–‰ ê²°ê³¼:**

 `ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì„œìš¸ì…ë‹ˆë‹¤.`

### ğŸ’¬ ChatPromptTemplate (ëŒ€í™”í˜•)

- ì—­í• (`system`, `human`, `ai`) ê¸°ë°˜ ë©”ì‹œì§€ êµ¬ì¡°
- `StrOutputParser`ì™€ í•¨ê»˜ ì‚¬ìš©

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

chat_template = ChatPromptTemplate.from_messages([
    ('system', 'ë‹¹ì‹ ì€ {lang}ìœ¼ë¡œ ë²ˆì—­í•˜ëŠ” ë²ˆì—­ê°€ì…ë‹ˆë‹¤.'),
    ('human', '{text}ë¥¼ ë²ˆì—­í•´ì£¼ì„¸ìš”.')
])

chain = chat_template | llm | StrOutputParser()
print(chain.invoke({'lang': 'ì˜ì–´', 'text': 'ë²„ê±°ê°€ ë¨¹ê³ ì‹¶ë‹¤'}))
```

**ğŸ‘‰ ì‹¤í–‰ ê²°ê³¼:**

 `I want to eat a burger.`

### ğŸ“š Few-Shot Prompting (ì˜ˆì‹œ ê¸°ë°˜)

- LLMì´ ì›í•˜ëŠ” **ì¶œë ¥ í˜•ì‹ê³¼ ì‚¬ê³  íë¦„**ì„ í•™ìŠµí•˜ë„ë¡ ì˜ˆì‹œ ì œê³µ
- ë³µì¡í•œ ì§ˆë¬¸ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´ ê°€ëŠ¥

```python
from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate

examples = [
    {"question": "ë„¤ì´ë²„ì˜ ì°½ë¦½ìëŠ” ì–¸ì œ íƒœì–´ë‚¬ë‚˜ìš”?",
     "answer": "...(ì˜ˆì‹œ ë‹µë³€ êµ¬ì¡°)"}
]

example_prompt = PromptTemplate.from_template(
    "Question:\n{question}\nAnswer:\n{answer}"
)

prompt = FewShotPromptTemplate(
    examples=examples,
    example_prompt=example_prompt,
    suffix="Question:\n{question}\nAnswer:",
    input_variables=["question"],
)

chain = prompt | llm | StrOutputParser()
print(chain.invoke({"question": "Googleì´ ì°½ë¦½ëœ ì—°ë„ì— Bill Gatesì˜ ë‚˜ì´ëŠ” ëª‡ ì‚´ì¸ê°€ìš”?"}))
```

**ğŸ‘‰ ì‹¤í–‰ ê²°ê³¼ (ìš”ì•½):**

- Google ì°½ë¦½ì—°ë„ í™•ì¸ (1998)
- Bill Gates ì¶œìƒ í™•ì¸ (1955)
- ë‚˜ì´ ê³„ì‚° â†’ `43ì„¸`

---

## ğŸŒ LangChain Hub

- ì „ ì„¸ê³„ ê°œë°œìë“¤ì´ ê³µìœ í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ì €ì¥ì†Œ
- ì‰½ê²Œ ë¶ˆëŸ¬ì™€ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥

```python
from langchain import hub
prompt = hub.pull('hwchase17/react')
print(prompt.template)
```

---

## âœ… ì¸ì‚¬ì´íŠ¸ & ìœ ì˜ì‚¬í•­

- **Prompt ì„¤ê³„ê°€ í•µì‹¬** â†’ ê²°ê³¼ í’ˆì§ˆì€ í”„ë¡¬í”„íŠ¸ì— ë‹¬ë ¤ìˆìŒ
- `|` ì—°ì‚°ìë¥¼ ì‚¬ìš©í•œ **Chain êµ¬ì¡°**ê°€ ì½”ë“œ ê°€ë…ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì— ìœ ë¦¬
- Few-Shotì€ ë‹¨ìˆœ ì˜ˆì‹œ ì œê³µì´ ì•„ë‹ˆë¼ **ì‚¬ê³  ê³¼ì •(Chain-of-Thought)ì„ ìœ ë„**í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ê¸°ë²•
- Hub í™œìš© ì‹œ ê²€ì¦ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ë¹ ë¥´ê²Œ ì ìš© ê°€ëŠ¥