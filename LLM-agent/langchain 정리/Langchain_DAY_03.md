# ğŸª„ Langchain

## âœï¸ DAY 03

## ğŸŒ ì›¹ ê²€ìƒ‰ (Web Search)

### ğŸ’¡ í•µì‹¬ ê°œë…

- **LLMì˜ í•œê³„**: í•™ìŠµ ì‹œì  ì´í›„ ì§€ì‹ ì—†ìŒ â†’ ìµœì‹  ì •ë³´ ë¶€ì¡±
- **í•´ê²°ì±…**: ì›¹ ê²€ìƒ‰ ë„êµ¬ ì—°ê²°
- **ëŒ€í‘œ ë„êµ¬**: `TavilySearch` â†’ ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë°˜í™˜

### ğŸ¤– ì—ì´ì „íŠ¸ (Agent)

- LLMì´ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•´ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
- ì£¼ìš” êµ¬ì„±ìš”ì†Œ:
    - **ë„êµ¬(tools)**: `TavilySearch`, RAG ë“±
    - **í”„ë¡¬í”„íŠ¸(prompt)**: LLMì—ê²Œ ë„êµ¬ ì‚¬ìš©ë²• ì•ˆë‚´
    - **ë©”ëª¨ë¦¬(memory)**: ëŒ€í™” ë§¥ë½ ìœ ì§€ (`ConversationBufferMemory`)
    - **AgentExecutor**: Agent ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ì²´ì¸
    

**ğŸ‘©â€ğŸ’» ì½”ë“œ ì˜ˆì‹œ**

```python
from langchain_tavily import TavilySearch
from langchain.agents import create_openai_tools_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.memory import ConversationBufferMemory

# 1. ë„êµ¬ ì •ì˜
search_tool = TavilySearch(max_results=5)
tools = [search_tool]

# 2. í”„ë¡¬í”„íŠ¸ ì„¤ì •
prompt = ChatPromptTemplate.from_messages([
    ('system', 'ë„ˆëŠ” í›Œë¥­í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ë°˜ë“œì‹œ ì›¹ ê²€ìƒ‰ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì •ë³´ë¥¼ ì–»ì–´.'),
    MessagesPlaceholder(variable_name='chat_history'),
    ('human', '{input}'),
    MessagesPlaceholder(variable_name='agent_scratchpad')
])

# 3. ë©”ëª¨ë¦¬ ì„¤ì •
memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)

# 4. Agent ìƒì„±
agent = create_openai_tools_agent(llm=llm, tools=tools, prompt=prompt)

# 5. Executorë¡œ ì‹¤í–‰
agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)

# ì‹¤í–‰
agent_executor.invoke({'input': 'ìš”ì¦˜ ì¸ê¸°ìˆëŠ” AI ëª¨ë¸ ì•Œë ¤ì¤˜'})
```

**ğŸ‘‰ ìµœì‹  ì •ë³´ ê¸°ë°˜ ë‹µë³€ ì œê³µ ê°€ëŠ¥**

---

## ğŸ” ê²€ìƒ‰-ì¦ê°• ìƒì„± (RAG: Retrieval-Augmented Generation)

### ğŸ’¡ í•µì‹¬ ê°œë…

- **RAG**: LLM + íŠ¹ì • ë¬¸ì„œ ê¸°ë°˜ ê²€ìƒ‰ ê²°í•©
- ë¬¸ì„œ ê¸°ë°˜ QA ì±—ë´‡ ì œì‘ì— í™œìš©

### âš™ï¸ RAG íŒŒì´í”„ë¼ì¸ (4ë‹¨ê³„)

1. **Load**: ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° (ì˜ˆ: `PyMuPDFLoader`)
2. **Split**: ë¬¸ì„œ ë¶„í•  (`RecursiveCharacterTextSplitter`)
3. **Embed**: ì„ë² ë”© ìƒì„± (`OpenAIEmbeddings`)
4. **Store**: ë²¡í„°DB ì €ì¥ (`FAISS`, `Chroma`)

### ğŸ› ï¸ Retriever Tool

- `vectorstore.as_retriever()` â†’ ê²€ìƒ‰ê¸° ìƒì„±
- `create_retriever_tool` â†’ Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ë„êµ¬ í˜•íƒœ**ë¡œ ë³€í™˜

**ğŸ‘©â€ğŸ’» ì½”ë“œ ì˜ˆì‹œ**

```python
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.tools.retriever import create_retriever_tool

# 1. ë¬¸ì„œ ë¡œë“œ
loader = PyMuPDFLoader('./data/spri.pdf')
docs = loader.load()

# 2. ë¶„í• 
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
split_docs = splitter.split_documents(docs)

# 3. ì„ë² ë”© + ë²¡í„°ìŠ¤í† ì–´
embedding = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(split_docs, embedding=embedding)
retriever = vectorstore.as_retriever()

# 4. Retriever Tool ìƒì„±
rag_tool = create_retriever_tool(
    retriever,
    name='pdf_search',
    description='PDF ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.'
)

# Agent ìƒì„± ì‹œ toolsì— rag_tool í¬í•¨
tools = [search_tool, rag_tool]
```

ğŸ‘‰ Agentê°€ **ì›¹ ê²€ìƒ‰**ê³¼ **ë¬¸ì„œ ê²€ìƒ‰**ì„ ìƒí™©ì— ë§ê²Œ ì„ íƒ

---

## âœ¨ ìµœì¢… ê²°ë¡ 

- **ì›¹ ê²€ìƒ‰ Agent**: ìµœì‹  ì •ë³´ / ì¼ë°˜ì  ì§ˆë¬¸ ì²˜ë¦¬ì— ìœ ë¦¬
- **RAG Agent**: íŠ¹ì • ë¬¸ì„œ ê¸°ë°˜ QAì— ê°•ë ¥
- **í†µí•© Agent**: ë‘ ë„êµ¬ë¥¼ ëª¨ë‘ í¬í•¨ â†’ ì§ˆë¬¸ ì„±ê²©ì— ë”°ë¼ ìë™ ì„ íƒ

---

## âœ… ì¸ì‚¬ì´íŠ¸ & ìœ ì˜ì‚¬í•­

- Agent ì„¤ê³„ ì‹œ **ë„êµ¬ ì„¤ëª…(description)**ì„ ëª…í™•íˆ ì‘ì„±í•´ì•¼ LLMì´ ì˜¬ë°”ë¥´ê²Œ ë„êµ¬ ì„ íƒ
- RAGëŠ” **ë°ì´í„° ê¸°ë°˜ QA**ì— ì í•© â†’ íšŒì‚¬ ë‚´ë¶€ ë¬¸ì„œ, ë²•ë¥ , ê¸°ìˆ  ë§¤ë‰´ì–¼ì— ìœ ìš©
- ì›¹ ê²€ìƒ‰ + RAG í†µí•© ì‹œ **ì‹¤ì œ ì„œë¹„ìŠ¤ ì±—ë´‡ ìˆ˜ì¤€**ì˜ ì—ì´ì „íŠ¸ êµ¬í˜„ ê°€ëŠ¥